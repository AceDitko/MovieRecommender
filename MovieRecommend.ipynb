{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MovieRecommend import Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mov = Movies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "mov.print_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov.preview_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = mov.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mov.preview_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = mov.get_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "mov.print_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "numerical_cols = ['BoxOffice', 'Metascore', 'Runtime', 'Year', 'imdbRating', 'Days to View', 'Days Since Release']\n",
    "categorical_cols = ['Rated', 'Format', 'Is_cinema', 'Is_weekday']\n",
    "plots = ['Plot']\n",
    "\n",
    "mlb_cols = ['Genre', 'Bag_of_words']\n",
    "#mlb_cols = 'Genre'\n",
    "\n",
    "form_cols = ['Genre', 'Actors', 'Director', 'Production', 'Writer']\n",
    "\n",
    "#for col in form_cols:\n",
    "#    col_str = col + \"_\"\n",
    "#    in_cols = [col for col in df.columns if col_str in col]\n",
    "#    for col2 in in_cols:\n",
    "#        categorical_cols.append(col2)\n",
    "\n",
    "print(categorical_cols)\n",
    "features = numerical_cols + categorical_cols + plots + mlb_cols\n",
    "\n",
    "for i in features:\n",
    "    df[i] = df[i].replace('N/A',np.NaN)\n",
    "    df[i] = df[i].replace('',np.NaN)\n",
    "    df[i] = df[i].replace(' ',np.NaN)\n",
    "    df[i] = df[i].replace('missing_value',np.NaN)\n",
    "\n",
    "numerical_transformer = SimpleImputer(missing_values=np.NaN,\n",
    "                                      strategy='median')\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(missing_values=np.NaN,\n",
    "                              strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "#mlb_transformer = MultiLabelBinarizer()\n",
    "\n",
    "#tfidf_transformer = TfidfVectorizer()\n",
    "\n",
    "#tfidf_transformer = TfidfVectorizer()\n",
    "#tfidf_transformer.fit(df['Plot'])\n",
    "#print(tfidf_transformer)\n",
    "#j = tfidf_transformer.transform(df['Plot'])\n",
    "\n",
    "#j_df = pd.DataFrame(j.toarray(), columns = tfidf_transformer.get_feature_names_out())\n",
    "#res = pd.concat([df, j_df], axis = 1)\n",
    "#print(res.head())\n",
    "\n",
    "#features += tfidf_transformer.get_feature_names_out().tolist()\n",
    "#print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class MultiHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Allow MultiLabelBinarizer to work with multiple input columns.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.mlbs = list()\n",
    "        self.n_columns = 0\n",
    "        self.categories_ = self.classes_ = list()\n",
    "\n",
    "    def fit(self, X:pd.DataFrame, y=None):\n",
    "        for i in range(X.shape[1]): # X can be of multiple columns\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            mlb.fit(X.iloc[:,i])\n",
    "            self.mlbs.append(mlb)\n",
    "            self.classes_.append(mlb.classes_)\n",
    "            self.n_columns += 1\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X:pd.DataFrame):\n",
    "        if self.n_columns == 0:\n",
    "            raise ValueError('Please fit the transformer first.')\n",
    "        if self.n_columns != X.shape[1]:\n",
    "            raise ValueError(f'The fit transformer deals with {self.n_columns} columns '\n",
    "                              f'while the input has {X.shape[1]}'\n",
    "                              )\n",
    "        result = list()\n",
    "        for i in range(self.n_columns):\n",
    "            result.append(self.mlbs[i].transform(X.iloc[:,i]))\n",
    "        result = np.concatenate(result, axis=1)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_transformer = MultiHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "        #('tfidf', Tfidf, plots)\n",
    "        ('mlb', mlb_transformer, mlb_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "#x = res[features]\n",
    "#y = res['True Rating']\n",
    "\n",
    "x=df[features]\n",
    "y=df['True Rating']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(x, y, random_state = 0)\n",
    "#print(X_train)\n",
    "#print(x[tfidf_transformer.get_feature_names()])\n",
    "print(type(df['Plot']))\n",
    "#print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Tfidf(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variables=None) -> None:\n",
    "        if not isinstance(variables, list):\n",
    "            self.variables = [variables]\n",
    "        else:\n",
    "            self.variables = variables\n",
    "       \n",
    "    def fit(self, X, y=None):\n",
    "        self.tfidf_transformer = TfidfVectorizer()\n",
    "        X = X[self.variables].squeeze()\n",
    "        #print(type(X[self.variables]))\n",
    "        self.tfidf_transformer.fit(X)\n",
    "        self.feature_names = self.tfidf_transformer.get_feature_names_out()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X[self.variables].squeeze()\n",
    "        #print(X)\n",
    "        j = self.tfidf_transformer.transform(X)\n",
    "        print(j)\n",
    "        j_df = pd.DataFrame(j.toarray(),\n",
    "                            columns = self.feature_names)\n",
    "        print(j_df)\n",
    "        return j_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_xfm = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Tfidf(variables=['Plot'])\n",
    "test.fit(X_train)\n",
    "j = test.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "params = {\"n_estimators\": [50, 100, 150, 200, 300, 500, 750, 1000],\n",
    "          #\"max_features\": ['auto', 'sqrt', 'log2'],\n",
    "          \"grow_policy\": ['depthwise', 'lossguide'],\n",
    "          \"max_depth\": [3, 4, 5],\n",
    "          \"min_child_weight\": [1, 2, 5, 10],\n",
    "          \"gamma\": [0.5, 1, 1.5, 2, 5],\n",
    "          \"subsample\": [0.4, 0.6, 0.8, 1.0],\n",
    "          \"colsample_bytree\": [0.6, 0.8, 1.0]\n",
    "          }\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=1000,\n",
    "                         learning_rate=0.05,\n",
    "                         n_jobs=-2)\n",
    "\n",
    "grid = GridSearchCV(xgb_model, \n",
    "                    param_grid=params,\n",
    "                    scoring=\"r2\",\n",
    "                    verbose=2,\n",
    "                    n_jobs = -3)\n",
    "\n",
    "#xgb_pipeline = Pipeline(steps=[\n",
    "#    ('preprocessor', preprocessor),\n",
    "#    ('model', xgb_model)\n",
    "#])\n",
    "\n",
    "grid_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('tfidf', Tfidf),\n",
    "    ('model', grid)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_search = False\n",
    "\n",
    "if new_search:\n",
    "    grid_pipeline.fit(X_train, y_train)\n",
    "    good_boys = grid.best_params_\n",
    "else:\n",
    "    #no nlp:\n",
    "    #good_boys = {'colsample_bytree': 0.6, 'gamma': 1.5, 'max_depth': 3, 'max_features': 'auto', 'min_child_weight': 1, 'n_estimators': 100, 'subsample': 1.0}\n",
    "    # nlp: \n",
    "    #good_boys = {'colsample_bytree': 0.6, 'gamma': 5, 'max_depth': 3, 'max_features': 'auto', 'min_child_weight': 1, 'n_estimators': 500, 'subsample': 0.8}\n",
    "    good_boys = {'colsample_bytree': 0.8, 'gamma': 1.5, 'grow_policy': 'depthwise', 'max_depth': 3, 'min_child_weight': 2, 'n_estimators': 100, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_boys = {'colsample_bytree': 0.8, \n",
    "             'gamma': 1.5, \n",
    "             'grow_policy': 'depthwise', \n",
    "             'max_depth': 3, \n",
    "             'min_child_weight': 2, \n",
    "             'n_estimators': 100, \n",
    "             'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(good_boys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#good_boys = {'colsample_bytree': 0.6, 'gamma': 5, 'max_depth': 3, 'max_features': 'auto', 'min_child_weight': 1, 'n_estimators': 500, 'subsample': 0.8}\n",
    "\n",
    "xgb_model = XGBRegressor(n_estimators=good_boys['n_estimators'],\n",
    "                         learning_rate=0.05,\n",
    "                         colsample_bytree=good_boys['colsample_bytree'],\n",
    "                         gamma=good_boys['gamma'],\n",
    "                         max_depth=good_boys['max_depth'],\n",
    "                         #max_features=good_boys['max_features'],\n",
    "                         min_child_weight=good_boys['min_child_weight'],\n",
    "                         subsample=good_boys['subsample'],\n",
    "                         grow_policy=good_boys['grow_policy'],\n",
    "                         n_jobs=-2)\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('tfidf', Tfidf),\n",
    "    ('model', xgb_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessor.fit(X_train, y_train)\n",
    "\n",
    "X_train_xfm = preprocessor.fit_transform(X_train)\n",
    "X_val_xfm = preprocessor.transform(X_val)\n",
    "\n",
    "xgb_pipeline.fit(X_train, y_train,\n",
    "                model__early_stopping_rounds=50,\n",
    "                model__eval_set=[(X_val_xfm, y_val)])\n",
    "\n",
    "preds = xgb_pipeline.predict(X_val)\n",
    "\n",
    "score = mean_absolute_error(preds, y_val)\n",
    "print(\"MAE: \" + str(score))\n",
    "\n",
    "score2 = mean_squared_error(preds, y_val)\n",
    "print(\"MSE: \" + str(score2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_df['True Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_xfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.histplot(new_df['True Rating'], bins=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "626ea8246a82476de376e6358a0371caa909bee52e0ad3b48293f4a510f9aa50"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
